import speech_recognition as sr
import text2emotion as te
import nltk
import streamlit as st

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.download('omw-1.4')
nltk.download('punkt_tab')

def record_speech():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print("ğŸ¤ Speak something to analyze emotion:")
        r.adjust_for_ambient_noise(source)
        audio = r.listen(source)

    try:
        print("ğŸ” Recognizing...")
        text = r.recognize_google(audio)
        print("ğŸ“ You said:", text)
        return text
    except sr.UnknownValueError:
        print("ğŸ˜• Could not understand audio")
        return ""
    except sr.RequestError:
        print("âš ï¸ Error connecting to Google API")
        return ""

def detect_emotion(text):
    if text:
        emotion = te.get_emotion(text)
        st.write(emotion)
        for i in emotion.keys():
            if emotion[i]!=0:
                st.info(f'major emotions in context is :- {i} with :- {emotion[i]}')
        print("ğŸ’¡ Detected Emotion:", emotion)
    else:
        print("âŒ No text to analyze.")

if __name__ == "__main__":
    st.title('ğŸ˜speech to emotion detectionğŸ˜’')
    a=st.button('Record')
    if a:
        st.write('ğŸ¤ Speak something to analyze emotion:')
        st.write("ğŸ” Recognizing...")
        text = record_speech()
        st.write('ğŸ“ You said:',text)
        detect_emotion(text)
